"""
Routes API pour le syst√®me OCR et pr√©traitement d'images
"""

from fastapi import APIRouter, UploadFile, File, HTTPException, Depends, BackgroundTasks
from fastapi.responses import FileResponse
from typing import List, Optional, Dict, Any
import tempfile
import shutil
import os
from pathlib import Path
import logging
import json
from datetime import datetime

from pydantic import BaseModel, Field
from sqlalchemy.orm import Session

# Import des modules internes
from core.database import get_db
from api.auth import get_current_user
from models.user import User
from models.document import Document, DocumentCategory
from ocr.image_preprocessor import ImagePreprocessor, preprocess_for_ocr
from ocr.tesseract_ocr import TesseractOCR, OCRResult
# Imports avanc√©s comment√©s temporairement √† cause de d√©pendances manquantes dans Docker
from ocr.trocr_ocr import TrOCREngine, TrOCRConfig
from ocr.hybrid_ocr import HybridOCREngine, HybridOCRConfig, OCRStrategy
from ocr.layoutlm_ocr import LayoutLMEngine, LayoutLMConfig
from ocr.table_detector import TableDetector, TableDetectorConfig, TableDetectionMethod
from ocr.entity_extractor import EntityExtractor, extract_document_metadata
from ocr.apple_silicon_optimizer import AppleSiliconOCROptimizer
from ocr.ocr_cache import OCRCacheManager

logger = logging.getLogger(__name__)

# Initialisation du router
router = APIRouter(prefix="/api/v1/ocr", tags=["OCR"])

# Initialisation des modules OCR (lazy loading)
_hybrid_ocr_engine = None
_trocr_engine = None
_layoutlm_engine = None
_table_detector = None
_entity_extractor = None
_apple_optimizer = None
_cache_manager = None

def get_hybrid_ocr_engine():
    global _hybrid_ocr_engine
    if _hybrid_ocr_engine is None:
        config = HybridOCRConfig(strategy=OCRStrategy.TROCR_FALLBACK)
        _hybrid_ocr_engine = HybridOCREngine(config)
    return _hybrid_ocr_engine

def get_cache_manager():
    global _cache_manager
    if _cache_manager is None:
        _cache_manager = OCRCacheManager({'type': 'hybrid'})
    return _cache_manager

# Sch√©mas Pydantic
class ImagePreprocessingRequest(BaseModel):
    """Requ√™te de pr√©traitement d'image"""
    apply_rotation_correction: bool = Field(default=True, description="Corriger la rotation automatiquement")
    apply_denoising: bool = Field(default=True, description="Appliquer le d√©bruitage")
    crop_borders: bool = Field(default=True, description="Supprimer les bordures automatiquement")
    optimize_contrast: bool = Field(default=True, description="Optimiser le contraste")
    split_pages: bool = Field(default=True, description="D√©couper les pages multiples")


class ImagePreprocessingResponse(BaseModel):
    """R√©ponse de pr√©traitement d'image"""
    success: bool
    message: str
    processed_files: List[str] = Field(default_factory=list)
    quality_scores: List[float] = Field(default_factory=list)
    processing_time: float
    original_size: Dict[str, int] = Field(default_factory=dict)
    processed_sizes: List[Dict[str, int]] = Field(default_factory=list)


class OCRProcessingRequest(BaseModel):
    """Requ√™te de traitement OCR complet"""
    document_id: Optional[str] = None
    category: Optional[DocumentCategory] = None
    preprocess: bool = Field(default=True, description="Appliquer le pr√©traitement")
    extract_entities: bool = Field(default=True, description="Extraire les entit√©s")
    generate_summary: bool = Field(default=False, description="G√©n√©rer un r√©sum√©")


class ZoneExtractionRequest(BaseModel):
    """Requ√™te d'extraction OCR par zones"""
    zones: List[List[int]] = Field(description="Liste des zones [x, y, width, height]")
    lang: Optional[str] = Field(default=None, description="Langue sp√©cifique pour l'OCR")
    preprocess: bool = Field(default=True, description="Appliquer le pr√©traitement")


class OCRProcessingResponse(BaseModel):
    """R√©ponse de traitement OCR"""
    success: bool
    message: str
    document_id: str
    extracted_text: str
    confidence_score: float
    detected_entities: Dict[str, Any] = Field(default_factory=dict)
    suggested_category: Optional[DocumentCategory] = None
    processing_time: float


class AdvancedOCRRequest(BaseModel):
    """Requ√™te OCR avanc√©e avec choix du moteur"""
    engine: str = Field(default="hybrid", description="Moteur OCR (tesseract, trocr, hybrid)")
    strategy: Optional[str] = Field(default="trocr_fallback", description="Strat√©gie pour moteur hybride")
    preprocess: bool = Field(default=True, description="Appliquer le pr√©traitement")
    extract_entities: bool = Field(default=True, description="Extraire les entit√©s")
    detect_tables: bool = Field(default=False, description="D√©tecter les tableaux")
    analyze_structure: bool = Field(default=False, description="Analyser la structure (LayoutLM)")
    use_cache: bool = Field(default=True, description="Utiliser le cache")


class StructureAnalysisRequest(BaseModel):
    """Requ√™te d'analyse de structure"""
    include_regions: bool = Field(default=True, description="Inclure les r√©gions d√©tect√©es")
    visualize: bool = Field(default=False, description="G√©n√©rer une visualisation")


class TableDetectionRequest(BaseModel):
    """Requ√™te de d√©tection de tableaux"""
    method: str = Field(default="hybrid", description="M√©thode de d√©tection")
    min_table_area: Optional[int] = Field(default=1000, description="Aire minimale des tableaux")
    extract_content: bool = Field(default=True, description="Extraire le contenu des tableaux")


class EntityExtractionRequest(BaseModel):
    """Requ√™te d'extraction d'entit√©s"""
    entity_types: Optional[List[str]] = Field(default=None, description="Types d'entit√©s √† extraire")
    include_context: bool = Field(default=True, description="Inclure le contexte")
    normalize_values: bool = Field(default=True, description="Normaliser les valeurs")


class AdvancedOCRResponse(BaseModel):
    """R√©ponse OCR avanc√©e"""
    success: bool
    message: str
    document_id: Optional[str] = None
    engine_used: str
    extracted_text: str
    confidence_score: float
    processing_time: float
    detected_entities: Dict[str, Any] = Field(default_factory=dict)
    detected_tables: List[Dict[str, Any]] = Field(default_factory=list)
    structure_regions: List[Dict[str, Any]] = Field(default_factory=list)
    cache_used: bool = False
    apple_silicon_optimized: bool = False


# Endpoints

@router.post("/preprocess", response_model=ImagePreprocessingResponse)
async def preprocess_image(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(..., description="Image √† pr√©traiter"),
    request: ImagePreprocessingRequest = Depends(),
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    Pr√©traite une image pour am√©liorer la qualit√© OCR
    
    - **file**: Image √† pr√©traiter (PNG, JPG, TIFF)
    - **request**: Options de pr√©traitement
    
    Retourne les images pr√©trait√©es avec m√©triques de qualit√©
    """
    start_time = datetime.now()
    
    try:
        # Validation du fichier
        if not file.filename:
            raise HTTPException(status_code=400, detail="Nom de fichier manquant")
        
        # V√©rification du format
        file_extension = Path(file.filename).suffix.lower()
        if file_extension not in {'.png', '.jpg', '.jpeg', '.tiff', '.tif', '.bmp'}:
            raise HTTPException(
                status_code=400, 
                detail=f"Format non support√©: {file_extension}. Formats accept√©s: PNG, JPG, TIFF, BMP"
            )
        
        # Sauvegarde temporaire du fichier
        with tempfile.NamedTemporaryFile(suffix=file_extension, delete=False) as tmp_file:
            shutil.copyfileobj(file.file, tmp_file)
            temp_input_path = tmp_file.name
        
        try:
            # Initialisation du pr√©processeur
            preprocessor = ImagePreprocessor()
            
            # Chargement et analyse de l'image originale
            original_image = preprocessor.load_image(temp_input_path)
            original_size = {
                "width": original_image.shape[1],
                "height": original_image.shape[0],
                "channels": original_image.shape[2] if len(original_image.shape) > 2 else 1
            }
            
            logger.info(f"Image charg√©e: {file.filename}, taille: {original_size}")
            
            # Configuration du pr√©traitement selon les options
            processed_image = original_image.copy()
            
            if request.apply_rotation_correction:
                processed_image = preprocessor.correct_rotation(processed_image)
                logger.debug("Correction de rotation appliqu√©e")
            
            if request.apply_denoising:
                processed_image = preprocessor.denoise_image(processed_image)
                logger.debug("D√©bruitage appliqu√©")
            
            if request.crop_borders:
                processed_image = preprocessor.detect_and_crop_borders(processed_image)
                logger.debug("Bordures supprim√©es")
            
            if request.optimize_contrast:
                processed_image = preprocessor.optimize_contrast_brightness(processed_image)
                logger.debug("Contraste optimis√©")
            
            # D√©coupage en pages si demand√©
            if request.split_pages:
                pages = preprocessor.split_pages(processed_image)
                logger.info(f"Pages d√©tect√©es: {len(pages)}")
            else:
                pages = [processed_image]
            
            # Cr√©ation du dossier de sortie temporaire
            with tempfile.TemporaryDirectory() as temp_output_dir:
                processed_files = []
                quality_scores = []
                processed_sizes = []
                
                for i, page in enumerate(pages):
                    # Nom du fichier de sortie
                    if len(pages) > 1:
                        output_filename = f"{Path(file.filename).stem}_page{i+1}_processed{file_extension}"
                    else:
                        output_filename = f"{Path(file.filename).stem}_processed{file_extension}"
                    
                    output_path = Path(temp_output_dir) / output_filename
                    
                    # Sauvegarde de la page
                    import cv2
                    cv2.imwrite(str(output_path), page)
                    
                    # Calcul du score de qualit√©
                    quality_score = preprocessor.get_image_quality_score(page)
                    quality_scores.append(quality_score)
                    
                    # Taille de l'image trait√©e
                    processed_size = {
                        "width": page.shape[1],
                        "height": page.shape[0],
                        "channels": page.shape[2] if len(page.shape) > 2 else 1
                    }
                    processed_sizes.append(processed_size)
                    
                    processed_files.append(output_filename)
                    
                    logger.info(f"Page {i+1} trait√©e: {output_filename}, qualit√©: {quality_score:.3f}")
                
                # Calcul du temps de traitement
                processing_time = (datetime.now() - start_time).total_seconds()
                
                # TODO: Ici on pourrait sauvegarder les fichiers dans un stockage permanent
                # et retourner des URLs ou des IDs pour les r√©cup√©rer plus tard
                
                return ImagePreprocessingResponse(
                    success=True,
                    message=f"Pr√©traitement r√©ussi: {len(pages)} page(s) trait√©e(s)",
                    processed_files=processed_files,
                    quality_scores=quality_scores,
                    processing_time=processing_time,
                    original_size=original_size,
                    processed_sizes=processed_sizes
                )
        
        finally:
            # Nettoyage du fichier temporaire
            if os.path.exists(temp_input_path):
                os.unlink(temp_input_path)
    
    except Exception as e:
        logger.error(f"Erreur lors du pr√©traitement de {file.filename}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur de pr√©traitement: {str(e)}")


@router.post("/process", response_model=OCRProcessingResponse)
async def process_document_ocr(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(..., description="Document √† traiter"),
    request: OCRProcessingRequest = Depends(),
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    Traitement OCR complet d'un document
    
    - **file**: Document √† analyser
    - **request**: Options de traitement OCR
    
    Effectue le pr√©traitement, l'OCR et l'extraction d'entit√©s
    """
    start_time = datetime.now()
    
    try:
        # Validation du fichier
        if not file.filename:
            raise HTTPException(status_code=400, detail="Nom de fichier manquant")
        
        logger.info(f"D√©but traitement OCR pour: {file.filename} (utilisateur: {current_user.email})")
        
        # Sauvegarde temporaire du fichier
        with tempfile.NamedTemporaryFile(suffix=Path(file.filename).suffix.lower(), delete=False) as tmp_file:
            shutil.copyfileobj(file.file, tmp_file)
            temp_input_path = tmp_file.name
        
        try:
            # Pipeline OCR complet
            ocr_result = None
            preprocessed_image = None
            
            # 1. Pr√©traitement si demand√©
            if request.preprocess:
                logger.info("Application du pr√©traitement...")
                preprocessor = ImagePreprocessor()
                preprocessed_image = preprocessor.process_image(temp_input_path)
                
                # Sauvegarder l'image pr√©trait√©e temporairement
                with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as processed_tmp:
                    import cv2
                    cv2.imwrite(processed_tmp.name, preprocessed_image)
                    processed_path = processed_tmp.name
            else:
                processed_path = temp_input_path
            
            # 2. OCR avec Tesseract
            logger.info("Ex√©cution OCR Tesseract...")
            tesseract_ocr = TesseractOCR()
            ocr_result = tesseract_ocr.extract_text(processed_path)
            
            # 3. Classification automatique basique
            suggested_category = DocumentCategory.NON_CLASSE
            
            # Heuristiques simples pour la classification
            text_lower = ocr_result.text.lower()
            if any(word in text_lower for word in ['facture', 'invoice', 'bill']):
                suggested_category = DocumentCategory.FACTURE
            elif any(word in text_lower for word in ['contrat', 'contract', 'accord']):
                suggested_category = DocumentCategory.CONTRAT
            elif any(word in text_lower for word in ['imp√¥t', 'taxe', 'fiscal']):
                suggested_category = DocumentCategory.IMPOT
            elif any(word in text_lower for word in ['rib', 'iban', 'bank']):
                suggested_category = DocumentCategory.RIB
            
            logger.info(f"Classification sugg√©r√©e: {suggested_category}")
            
            # 4. Analyse avanc√©e avec Mistral MLX (si disponible)
            mistral_analysis = None
            mistral_category_suggestion = None
            summary = ""
            
            if ocr_result.text and len(ocr_result.text.strip()) > 50:
                try:
                    # Appel direct au service Mistral MLX natif
                    mistral_result = await _call_mistral_service_direct(ocr_result.text)
                    
                    if mistral_result.get('success'):
                        result_data = mistral_result.get('result', {})
                        mistral_category_suggestion = result_data.get('document_type')
                        summary = result_data.get('summary', '').strip()
                        
                        logger.info(f"ü§ñ Analyse Mistral: type={mistral_category_suggestion}, summary={len(summary)} chars")
                        
                        # Mapping des types Mistral vers nos cat√©gories
                        mistral_to_our_categories = {
                            'facture': DocumentCategory.FACTURE,
                            'rib': DocumentCategory.RIB, 
                            'contrat': DocumentCategory.CONTRAT,
                            'attestation': DocumentCategory.ATTESTATION,
                            'courrier': DocumentCategory.COURRIER,
                            'rapport': DocumentCategory.NON_CLASSE,
                            'autre': DocumentCategory.NON_CLASSE
                        }
                        
                        mistral_mapped_category = mistral_to_our_categories.get(mistral_category_suggestion, DocumentCategory.NON_CLASSE)
                        
                        # Si Mistral est confiant, utiliser sa suggestion
                        mistral_confidence = result_data.get('confidence', 0)
                        if mistral_confidence > 0.7:
                            suggested_category = mistral_mapped_category
                            logger.info(f"üîÑ Classification Mistral utilis√©e: {suggested_category} (confiance: {mistral_confidence:.2f})")
                        
                except Exception as e:
                    logger.warning(f"Analyse Mistral √©chou√©e: {e}")
            
            # 5. Classification hybride finale avec classification bas√©e sur r√®gles
            from services.document_classifier import get_document_classifier
            
            try:
                classifier = get_document_classifier()
                classification_result = classifier.classify_document(
                    filename=file.filename,
                    ocr_text=ocr_result.text,
                    entities=list(ocr_result.detected_entities.keys()) if ocr_result.detected_entities else []
                )
                
                final_category = classification_result.category
                final_confidence = classification_result.confidence
                
                # Combiner avec Mistral si disponible
                if mistral_category_suggestion:
                    # Booster la confiance si les deux m√©thodes s'accordent
                    if suggested_category == DocumentCategory(final_category):
                        final_confidence = min(0.98, final_confidence * 1.2)
                        logger.info(f"üéØ Accord classification: {final_category} (confiance boost√©e: {final_confidence:.2f})")
                
                suggested_category = DocumentCategory(final_category)
                
                logger.info(f"üè∑Ô∏è Classification finale: {final_category} (confiance: {final_confidence:.2f})")
                logger.info(f"   üìã Raisonnement: {classification_result.reasoning}")
                
            except Exception as e:
                logger.warning(f"Classification par r√®gles √©chou√©e: {e}")
                final_confidence = ocr_result.confidence
            
            # 6. Calcul de la taille du fichier
            file_size = os.path.getsize(temp_input_path)
            
            # 7. Sauvegarde en base avec toutes les informations
            document = Document(
                filename=file.filename,
                original_filename=file.filename,
                file_size=file_size,
                mime_type=file.content_type or "application/octet-stream",
                user_id=current_user.id,
                category=request.category or suggested_category.value,
                ocr_text=ocr_result.text,
                confidence_score=final_confidence,
                entities=list(ocr_result.detected_entities.keys()) if ocr_result.detected_entities else [],
                custom_tags=[suggested_category.value],
                summary=summary if summary else f"Document {suggested_category.value} analys√© automatiquement.",
                processed_at=datetime.utcnow()
            )
            
            db.add(document)
            db.commit()
            db.refresh(document)
            
            # Temps de traitement total
            processing_time = (datetime.now() - start_time).total_seconds()
            
            logger.info(f"OCR termin√©: {ocr_result.word_count} mots, "
                       f"confiance: {ocr_result.confidence:.3f}, "
                       f"temps: {processing_time:.2f}s")
            
            return OCRProcessingResponse(
                success=True,
                message=f"OCR + IA r√©ussi: {ocr_result.word_count} mots extraits, classification {suggested_category.value}",
                document_id=str(document.id),
                extracted_text=ocr_result.text,
                confidence_score=final_confidence,
                detected_entities=ocr_result.detected_entities,
                suggested_category=suggested_category,
                processing_time=processing_time
            )
            
        finally:
            # Nettoyage des fichiers temporaires
            for path in [temp_input_path, processed_path if 'processed_path' in locals() and processed_path != temp_input_path else None]:
                if path and os.path.exists(path):
                    os.unlink(path)
    
    except Exception as e:
        logger.error(f"Erreur lors du traitement OCR de {file.filename}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur de traitement OCR: {str(e)}")


@router.post("/extract-zones")
async def extract_text_from_zones(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(..., description="Image √† analyser par zones"),
    request: ZoneExtractionRequest = Depends(),
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    Extrait le texte de zones sp√©cifiques de l'image
    
    - **file**: Image √† analyser
    - **zones**: Liste des zones [x, y, width, height]
    - **lang**: Langue pour l'OCR (auto-d√©tection si non sp√©cifi√©e)
    - **preprocess**: Appliquer le pr√©traitement
    
    Retourne le texte extrait pour chaque zone avec positions
    """
    start_time = datetime.now()
    
    try:
        # Validation du fichier
        if not file.filename:
            raise HTTPException(status_code=400, detail="Nom de fichier manquant")
        
        # Validation des zones
        if not request.zones:
            raise HTTPException(status_code=400, detail="Aucune zone sp√©cifi√©e")
        
        for i, zone in enumerate(request.zones):
            if len(zone) != 4:
                raise HTTPException(
                    status_code=400, 
                    detail=f"Zone {i+1} invalide: doit contenir [x, y, width, height]"
                )
            if any(coord < 0 for coord in zone):
                raise HTTPException(
                    status_code=400,
                    detail=f"Zone {i+1} invalide: coordonn√©es n√©gatives"
                )
        
        logger.info(f"Extraction par zones pour: {file.filename} ({len(request.zones)} zones)")
        
        # Sauvegarde temporaire
        with tempfile.NamedTemporaryFile(suffix=Path(file.filename).suffix.lower(), delete=False) as tmp_file:
            shutil.copyfileobj(file.file, tmp_file)
            temp_input_path = tmp_file.name
        
        try:
            # Pr√©traitement si demand√©
            if request.preprocess:
                preprocessor = ImagePreprocessor()
                preprocessed_image = preprocessor.process_image(temp_input_path)
                
                with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as processed_tmp:
                    import cv2
                    cv2.imwrite(processed_tmp.name, preprocessed_image)
                    processed_path = processed_tmp.name
            else:
                processed_path = temp_input_path
            
            # Conversion des zones en tuples
            zones_tuples = [tuple(zone) for zone in request.zones]
            
            # Extraction OCR par zones
            tesseract_ocr = TesseractOCR()
            zone_results = tesseract_ocr.extract_text_from_zones(
                processed_path, 
                zones_tuples, 
                lang=request.lang
            )
            
            # Temps de traitement
            processing_time = (datetime.now() - start_time).total_seconds()
            
            # Formatage de la r√©ponse
            zone_responses = []
            total_words = 0
            
            for i, result in enumerate(zone_results):
                zone_response = {
                    "zone_id": i + 1,
                    "zone_coords": request.zones[i],
                    "extracted_text": result.text,
                    "confidence": result.confidence,
                    "word_count": result.word_count,
                    "line_count": result.line_count,
                    "detected_entities": result.detected_entities,
                    "quality_metrics": result.quality_metrics
                }
                zone_responses.append(zone_response)
                total_words += result.word_count
            
            logger.info(f"Extraction zones termin√©e: {total_words} mots total, "
                       f"temps: {processing_time:.2f}s")
            
            return {
                "success": True,
                "message": f"Extraction r√©ussie sur {len(request.zones)} zones",
                "total_zones": len(request.zones),
                "total_words": total_words,
                "processing_time": processing_time,
                "zones": zone_responses
            }
            
        finally:
            # Nettoyage
            for path in [temp_input_path, processed_path if 'processed_path' in locals() and processed_path != temp_input_path else None]:
                if path and os.path.exists(path):
                    os.unlink(path)
    
    except Exception as e:
        logger.error(f"Erreur extraction zones {file.filename}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur d'extraction: {str(e)}")


@router.get("/quality-check/{file_id}")
async def check_image_quality(
    file_id: str,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    V√©rifie la qualit√© d'une image pour OCR
    
    - **file_id**: ID du fichier √† analyser
    
    Retourne un score de qualit√© et des recommandations
    """
    try:
        # TODO: R√©cup√©rer le fichier par son ID
        # document = db.query(Document).filter(Document.id == file_id).first()
        
        # Simulation pour l'instant
        quality_metrics = {
            "overall_score": 0.85,
            "sharpness": 0.90,
            "contrast": 0.80,
            "resolution": 0.85,
            "noise_level": 0.15,
            "recommendations": [
                "Qualit√© acceptable pour OCR",
                "L√©g√®re am√©lioration du contraste recommand√©e"
            ]
        }
        
        return {
            "success": True,
            "file_id": file_id,
            "quality_metrics": quality_metrics
        }
    
    except Exception as e:
        logger.error(f"Erreur lors de l'analyse qualit√©: {str(e)}")
        raise HTTPException(status_code=500, details=f"Erreur d'analyse: {str(e)}")


@router.post("/advanced", response_model=AdvancedOCRResponse)
async def advanced_ocr_processing(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(..., description="Document √† analyser"),
    request: AdvancedOCRRequest = Depends(),
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    Traitement OCR avanc√© avec choix du moteur et fonctionnalit√©s √©tendues
    
    - **file**: Document √† analyser
    - **request**: Configuration avanc√©e
    
    Utilise les derniers mod√®les (TrOCR, LayoutLM) avec cache intelligent
    """
    start_time = datetime.now()
    
    try:
        # Validation du fichier
        if not file.filename:
            raise HTTPException(status_code=400, detail="Nom de fichier manquant")
        
        logger.info(f"OCR avanc√© d√©marr√©: {file.filename} (moteur: {request.engine})")
        
        # Sauvegarde temporaire
        with tempfile.NamedTemporaryFile(suffix=Path(file.filename).suffix.lower(), delete=False) as tmp_file:
            shutil.copyfileobj(file.file, tmp_file)
            temp_input_path = tmp_file.name
        
        try:
            # Initialisation des composants
            cache_manager = get_cache_manager() if request.use_cache else None
            detected_tables = []
            structure_regions = []
            apple_silicon_optimized = False
            
            # V√©rifier le cache si activ√©
            cache_used = False
            if cache_manager:
                cached_result = cache_manager.get_cached_result(
                    temp_input_path, 
                    request.engine, 
                    request.dict()
                )
                if cached_result:
                    cache_used = True
                    logger.info("R√©sultat trouv√© dans le cache")
                    
                    return AdvancedOCRResponse(
                        success=True,
                        message="R√©sultat OCR r√©cup√©r√© du cache",
                        engine_used=request.engine,
                        extracted_text=cached_result.text,
                        confidence_score=cached_result.confidence,
                        processing_time=0.1,  # Temps de cache quasi-instantan√©
                        detected_entities=cached_result.detected_entities,
                        cache_used=True
                    )
            
            # Optimisation Apple Silicon
            apple_optimizer = AppleSiliconOCROptimizer()
            if apple_optimizer.chip_info["is_apple_silicon"]:
                apple_silicon_optimized = True
                logger.info("Optimisations Apple Silicon activ√©es")
            
            # S√©lection et ex√©cution du moteur OCR
            ocr_result = None
            engine_used = request.engine
            
            if request.engine == "hybrid":
                # Moteur hybride
                hybrid_engine = get_hybrid_ocr_engine()
                
                # Mapper la strat√©gie
                strategy_map = {
                    "trocr_only": OCRStrategy.TROCR_ONLY,
                    "tesseract_only": OCRStrategy.TESSERACT_ONLY,
                    "trocr_fallback": OCRStrategy.TROCR_FALLBACK,
                    "best_confidence": OCRStrategy.BEST_CONFIDENCE,
                    "ensemble": OCRStrategy.ENSEMBLE
                }
                strategy = strategy_map.get(request.strategy, OCRStrategy.TROCR_FALLBACK)
                
                ocr_result = hybrid_engine.extract_text(temp_input_path, strategy=strategy)
                engine_used = f"hybrid_{request.strategy}"
                
            elif request.engine == "trocr":
                # TrOCR uniquement
                trocr_config = TrOCRConfig()
                trocr_engine = TrOCREngine(trocr_config)
                ocr_result = trocr_engine.extract_text(temp_input_path, preprocess=request.preprocess)
                
            elif request.engine == "tesseract":
                # Tesseract uniquement
                tesseract_engine = TesseractOCR()
                ocr_result = tesseract_engine.extract_text(temp_input_path, preprocess=request.preprocess)
                
            else:
                raise HTTPException(status_code=400, detail=f"Moteur OCR non support√©: {request.engine}")
            
            if not ocr_result:
                raise HTTPException(status_code=500, detail="√âchec de l'extraction OCR")
            
            # D√©tection de tableaux si demand√©e
            if request.detect_tables:
                try:
                    table_config = TableDetectorConfig(detection_method=TableDetectionMethod.HYBRID)
                    table_detector = TableDetector(table_config)
                    tables = table_detector.detect_tables(temp_input_path, preprocess=request.preprocess)
                    
                    for table in tables:
                        detected_tables.append(table_detector.extract_table_as_dict(table))
                    
                    logger.info(f"Tableaux d√©tect√©s: {len(detected_tables)}")
                    
                except Exception as e:
                    logger.error(f"Erreur d√©tection tableaux: {e}")
            
            # Analyse de structure si demand√©e
            if request.analyze_structure:
                try:
                    layoutlm_config = LayoutLMConfig()
                    layoutlm_engine = LayoutLMEngine(layoutlm_config)
                    _, regions = layoutlm_engine.extract_structured_text(temp_input_path, preprocess=request.preprocess)
                    
                    for region in regions:
                        structure_regions.append({
                            "type": region.region_type.value,
                            "text": region.text,
                            "bbox": region.bbox,
                            "confidence": region.confidence
                        })
                    
                    logger.info(f"R√©gions structur√©es: {len(structure_regions)}")
                    
                except Exception as e:
                    logger.error(f"Erreur analyse structure: {e}")
            
            # Extraction d'entit√©s avanc√©e si demand√©e
            if request.extract_entities:
                try:
                    entity_extractor = EntityExtractor()
                    entity_result = entity_extractor.extract_entities(ocr_result.text)
                    
                    # Enrichir les entit√©s d√©tect√©es
                    enriched_entities = entity_extractor.get_structured_summary(entity_result)
                    ocr_result.detected_entities.update(enriched_entities['entities_by_type'])
                    
                except Exception as e:
                    logger.error(f"Erreur extraction entit√©s: {e}")
            
            # Sauvegarde en base de donn√©es
            file_size = os.path.getsize(temp_input_path)
            document = Document(
                filename=file.filename,
                original_filename=file.filename,
                file_size=file_size,
                mime_type=file.content_type or "application/octet-stream",
                user_id=current_user.id,
                category=DocumentCategory.NON_CLASSE,  # Classification automatique plus tard
                ocr_text=ocr_result.text,
                confidence_score=ocr_result.confidence
            )
            
            db.add(document)
            db.commit()
            db.refresh(document)
            
            # Mise en cache du r√©sultat
            if cache_manager:
                cache_manager.cache_result(
                    temp_input_path,
                    engine_used,
                    ocr_result,
                    request.dict()
                )
            
            # Temps de traitement total
            processing_time = (datetime.now() - start_time).total_seconds()
            
            logger.info(f"OCR avanc√© termin√©: {ocr_result.word_count} mots, "
                       f"confiance: {ocr_result.confidence:.3f}, "
                       f"temps: {processing_time:.2f}s")
            
            return AdvancedOCRResponse(
                success=True,
                message=f"OCR avanc√© r√©ussi: {ocr_result.word_count} mots extraits",
                document_id=str(document.id),
                engine_used=engine_used,
                extracted_text=ocr_result.text,
                confidence_score=ocr_result.confidence,
                processing_time=processing_time,
                detected_entities=ocr_result.detected_entities,
                detected_tables=detected_tables,
                structure_regions=structure_regions,
                cache_used=cache_used,
                apple_silicon_optimized=apple_silicon_optimized
            )
            
        finally:
            # Nettoyage
            if os.path.exists(temp_input_path):
                os.unlink(temp_input_path)
    
    except Exception as e:
        logger.error(f"Erreur OCR avanc√© {file.filename}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur OCR avanc√©: {str(e)}")


@router.post("/analyze-structure")
async def analyze_document_structure(
    file: UploadFile = File(..., description="Document √† analyser"),
    request: StructureAnalysisRequest = Depends(),
    current_user: User = Depends(get_current_user)
):
    """
    Analyse la structure d'un document avec LayoutLMv3
    
    - **file**: Document √† analyser
    - **request**: Options d'analyse
    
    Retourne les r√©gions d√©tect√©es et leur classification
    """
    try:
        if not file.filename:
            raise HTTPException(status_code=400, detail="Nom de fichier manquant")
        
        with tempfile.NamedTemporaryFile(suffix=Path(file.filename).suffix.lower(), delete=False) as tmp_file:
            shutil.copyfileobj(file.file, tmp_file)
            temp_input_path = tmp_file.name
        
        try:
            layoutlm_config = LayoutLMConfig()
            layoutlm_engine = LayoutLMEngine(layoutlm_config)
            
            ocr_result, regions = layoutlm_engine.extract_structured_text(temp_input_path)
            
            response_data = {
                "success": True,
                "message": f"Structure analys√©e: {len(regions)} r√©gions d√©tect√©es",
                "extracted_text": ocr_result.text,
                "confidence": ocr_result.confidence,
                "processing_time": ocr_result.processing_time
            }
            
            if request.include_regions:
                response_data["regions"] = [
                    {
                        "type": region.region_type.value,
                        "text": region.text,
                        "bbox": region.bbox,
                        "confidence": region.confidence,
                        "tokens": region.tokens if hasattr(region, 'tokens') else []
                    }
                    for region in regions
                ]
            
            return response_data
            
        finally:
            if os.path.exists(temp_input_path):
                os.unlink(temp_input_path)
    
    except Exception as e:
        logger.error(f"Erreur analyse structure: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur d'analyse: {str(e)}")


@router.post("/detect-tables")
async def detect_document_tables(
    file: UploadFile = File(..., description="Document √† analyser"),
    request: TableDetectionRequest = Depends(),
    current_user: User = Depends(get_current_user)
):
    """
    D√©tecte et extrait les tableaux d'un document
    
    - **file**: Document √† analyser
    - **request**: Configuration de la d√©tection
    
    Retourne les tableaux d√©tect√©s avec leur contenu
    """
    try:
        if not file.filename:
            raise HTTPException(status_code=400, detail="Nom de fichier manquant")
        
        with tempfile.NamedTemporaryFile(suffix=Path(file.filename).suffix.lower(), delete=False) as tmp_file:
            shutil.copyfileobj(file.file, tmp_file)
            temp_input_path = tmp_file.name
        
        try:
            # Configuration du d√©tecteur
            method_map = {
                "hough_lines": TableDetectionMethod.HOUGH_LINES,
                "contours": TableDetectionMethod.CONTOURS,
                "morphology": TableDetectionMethod.MORPHOLOGY,
                "hybrid": TableDetectionMethod.HYBRID
            }
            
            detection_method = method_map.get(request.method, TableDetectionMethod.HYBRID)
            
            table_config = TableDetectorConfig(
                detection_method=detection_method,
                min_table_area=request.min_table_area or 1000
            )
            
            table_detector = TableDetector(table_config)
            tables = table_detector.detect_tables(temp_input_path)
            
            response_tables = []
            for table in tables:
                table_data = table_detector.extract_table_as_dict(table)
                if request.extract_content:
                    response_tables.append(table_data)
                else:
                    # Retourner seulement les m√©tadonn√©es
                    response_tables.append({
                        "bbox": table_data["bbox"],
                        "dimensions": table_data["dimensions"],
                        "confidence": table_data["confidence"],
                        "extraction_method": table_data["extraction_method"]
                    })
            
            return {
                "success": True,
                "message": f"D√©tection termin√©e: {len(response_tables)} tableaux trouv√©s",
                "tables": response_tables,
                "detection_method": request.method
            }
            
        finally:
            if os.path.exists(temp_input_path):
                os.unlink(temp_input_path)
    
    except Exception as e:
        logger.error(f"Erreur d√©tection tableaux: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur de d√©tection: {str(e)}")


@router.post("/extract-entities")
async def extract_document_entities(
    file: UploadFile = File(..., description="Document √† analyser"),
    request: EntityExtractionRequest = Depends(),
    current_user: User = Depends(get_current_user)
):
    """
    Extrait les entit√©s sp√©cifiques d'un document
    
    - **file**: Document √† analyser
    - **request**: Configuration de l'extraction
    
    Retourne les entit√©s d√©tect√©es avec normalisation
    """
    try:
        if not file.filename:
            raise HTTPException(status_code=400, detail="Nom de fichier manquant")
        
        with tempfile.NamedTemporaryFile(suffix=Path(file.filename).suffix.lower(), delete=False) as tmp_file:
            shutil.copyfileobj(file.file, tmp_file)
            temp_input_path = tmp_file.name
        
        try:
            # OCR basique pour obtenir le texte
            tesseract_engine = TesseractOCR()
            ocr_result = tesseract_engine.extract_text(temp_input_path)
            
            # Extraction d'entit√©s
            entity_extractor = EntityExtractor()
            entity_result = entity_extractor.extract_entities(
                ocr_result.text, 
                entity_types=request.entity_types
            )
            
            # M√©tadonn√©es du document
            document_metadata = extract_document_metadata(ocr_result.text)
            
            response_data = {
                "success": True,
                "message": f"Extraction termin√©e: {len(entity_result.entities)} entit√©s trouv√©es",
                "extracted_text": ocr_result.text if request.include_context else None,
                "processing_time": entity_result.processing_time,
                "entity_counts": entity_result.entity_counts,
                "entities": []
            }
            
            # Formatter les entit√©s
            for entity in entity_result.entities:
                entity_data = {
                    "type": entity.entity_type,
                    "value": entity.value,
                    "confidence": entity.confidence,
                    "position": {
                        "start": entity.start_position,
                        "end": entity.end_position
                    }
                }
                
                if request.normalize_values and entity.normalized_value:
                    entity_data["normalized_value"] = str(entity.normalized_value)
                
                if request.include_context and entity.context:
                    entity_data["context"] = entity.context
                
                response_data["entities"].append(entity_data)
            
            # Ajouter les m√©tadonn√©es du document
            response_data["document_metadata"] = document_metadata
            
            return response_data
            
        finally:
            if os.path.exists(temp_input_path):
                os.unlink(temp_input_path)
    
    except Exception as e:
        logger.error(f"Erreur extraction entit√©s: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur d'extraction: {str(e)}")


@router.get("/cache/stats")
async def get_cache_statistics(
    current_user: User = Depends(get_current_user)
):
    """
    Retourne les statistiques du cache OCR
    """
    try:
        cache_manager = get_cache_manager()
        stats = cache_manager.get_cache_stats()
        
        return {
            "success": True,
            "cache_stats": stats
        }
    
    except Exception as e:
        logger.error(f"Erreur stats cache: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur: {str(e)}")


@router.delete("/cache")
async def clear_ocr_cache(
    current_user: User = Depends(get_current_user)
):
    """
    Vide le cache OCR
    """
    try:
        cache_manager = get_cache_manager()
        cache_manager.clear_all_cache()
        
        return {
            "success": True,
            "message": "Cache OCR vid√© avec succ√®s"
        }
    
    except Exception as e:
        logger.error(f"Erreur vidage cache: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur: {str(e)}")


@router.get("/supported-formats")
async def get_supported_formats():
    """
    Retourne la liste des formats d'image support√©s
    """
    return {
        "success": True,
        "supported_formats": [
            {
                "extension": ".jpg",
                "mime_types": ["image/jpeg"],
                "description": "JPEG image"
            },
            {
                "extension": ".jpeg", 
                "mime_types": ["image/jpeg"],
                "description": "JPEG image"
            },
            {
                "extension": ".png",
                "mime_types": ["image/png"],
                "description": "PNG image"
            },
            {
                "extension": ".tiff",
                "mime_types": ["image/tiff"],
                "description": "TIFF image"
            },
            {
                "extension": ".tif",
                "mime_types": ["image/tiff"],
                "description": "TIFF image"
            },
            {
                "extension": ".bmp",
                "mime_types": ["image/bmp"],
                "description": "Bitmap image"
            }
        ],
        "max_file_size": "50MB",
        "recommendations": [
            "Utilisez des images haute r√©solution (minimum 300 DPI)",
            "√âvitez les images floues ou pixelis√©es",
            "Le format PNG est recommand√© pour les documents scann√©s",
            "TIFF est id√©al pour les documents de qualit√© archivage"
        ]
    }


async def _call_mistral_service_direct(text: str) -> dict:
    """Appel direct au service Mistral MLX natif avec gestion d'erreur robuste"""
    try:
        import httpx
        import os
        
        # Configuration service MLX
        mistral_host = "localhost"  # Architecture native macOS
        
        # Limiter le texte pour √©viter les timeouts
        text_excerpt = text[:2000] if len(text) > 2000 else text
        
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(
                f"http://{mistral_host}:8004/analyze",
                json={
                    "text": text_excerpt,
                    "analysis_types": ["classification", "summarization", "key_extraction"]
                }
            )
            
            if response.status_code == 200:
                return response.json()
            else:
                logger.warning(f"Erreur API Mistral: {response.status_code}")
                return {"success": False, "error": f"HTTP {response.status_code}"}
                
    except Exception as e:
        logger.warning(f"Erreur connexion Mistral: {e}")
        return {"success": False, "error": str(e)}


@router.get("/preprocessing-options")
async def get_preprocessing_options():
    """
    Retourne les options disponibles pour le pr√©traitement
    """
    return {
        "success": True,
        "options": {
            "rotation_correction": {
                "description": "D√©tecte et corrige automatiquement la rotation du document",
                "recommended": True,
                "processing_time": "medium"
            },
            "denoising": {
                "description": "Supprime le bruit de l'image pour am√©liorer la lisibilit√©",
                "recommended": True,
                "processing_time": "medium"
            },
            "border_cropping": {
                "description": "D√©tecte et supprime les bordures inutiles",
                "recommended": True,
                "processing_time": "fast"
            },
            "contrast_optimization": {
                "description": "Optimise le contraste et la luminosit√© pour l'OCR",
                "recommended": True,
                "processing_time": "fast"
            },
            "page_splitting": {
                "description": "D√©coupe automatiquement les pages multiples (livre ouvert, etc.)",
                "recommended": False,
                "processing_time": "fast"
            }
        }
    }