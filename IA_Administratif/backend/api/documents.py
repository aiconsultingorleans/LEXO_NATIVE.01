"""
Endpoints de gestion des documents
"""

from __future__ import annotations

from fastapi import APIRouter, Depends, HTTPException, UploadFile, File, status, BackgroundTasks
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from pydantic import BaseModel
from typing import List
from datetime import datetime
from pathlib import Path

from core.database import get_db
from models.user import User
from models.document import Document, DocumentCategory
from api.auth import get_current_user
from services.ocr_watcher import OCRFileHandler
import logging

router = APIRouter()


# Schemas
class DocumentResponse(BaseModel):
    id: int
    filename: str
    category: str
    confidence_score: float
    ocr_text: str | None
    entities: List[str] = []
    amount: float | None
    document_date: datetime | None
    custom_tags: List[str] = []
    summary: str | None = None
    created_at: datetime
    processed_at: datetime | None

    class Config:
        from_attributes = True


class DocumentsListResponse(BaseModel):
    documents: List[DocumentResponse]
    total: int
    page: int
    limit: int


# Endpoints
@router.get("/", response_model=DocumentsListResponse)
async def get_documents(
    page: int = 1,
    limit: int = 20,
    category: str | None = None,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """R√©cup√®re la liste des documents de l'utilisateur"""
    query = select(Document).where(Document.user_id == current_user.id)
    
    if category:
        query = query.where(Document.category == category)
    
    # Count total
    count_result = await db.execute(query)
    total = len(count_result.scalars().all())
    
    # Paginated results
    offset = (page - 1) * limit
    query = query.offset(offset).limit(limit).order_by(Document.created_at.desc())
    
    result = await db.execute(query)
    documents = result.scalars().all()
    
    return DocumentsListResponse(
        documents=documents,
        total=total,
        page=page,
        limit=limit
    )


# Schemas pour structure dossiers OCR
class FolderItem(BaseModel):
    name: str
    path: str
    type: str  # 'folder' ou 'file'
    count: int  # nombre de fichiers dans le dossier
    children: List[FolderItem] = []


class OCRFolderStructureResponse(BaseModel):
    folders: List[FolderItem]
    total_files: int


@router.get("/ocr-folder-structure", response_model=OCRFolderStructureResponse)
async def get_ocr_folder_structure(
    current_user: User = Depends(get_current_user)
):
    """R√©cup√®re la structure hi√©rarchique des dossiers OCR avec comptage de fichiers"""
    import os
    from pathlib import Path
    
    # Chemin vers le dossier OCR (configurable)
    ocr_base_path = Path(os.getenv("OCR_FOLDER_PATH", "/Users/stephaneansel/Documents/LEXO_v1/OCR"))
    
    if not ocr_base_path.exists():
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Dossier OCR introuvable"
        )
    
    # Extensions support√©es
    supported_extensions = {'.pdf', '.png', '.jpg', '.jpeg', '.tiff', '.bmp'}
    
    def scan_folder(folder_path: Path, max_depth: int = 3, current_depth: int = 0) -> FolderItem:
        """Scanne r√©cursivement un dossier et retourne sa structure"""
        file_count = 0
        children = []
        
        try:
            # Compter les fichiers dans ce dossier
            for item in folder_path.iterdir():
                if item.is_file() and item.suffix.lower() in supported_extensions:
                    file_count += 1
                elif item.is_dir() and current_depth < max_depth:
                    # Scanner r√©cursivement les sous-dossiers
                    child_folder = scan_folder(item, max_depth, current_depth + 1)
                    children.append(child_folder)
                    file_count += child_folder.count
        except PermissionError:
            # Ignorer les dossiers sans permission
            pass
        
        return FolderItem(
            name=folder_path.name,
            path=str(folder_path.relative_to(ocr_base_path)),
            type='folder',
            count=file_count,
            children=children
        )
    
    # Scanner tous les dossiers du r√©pertoire OCR
    all_folders = []
    total_files = 0
    
    try:
        for item in ocr_base_path.iterdir():
            if item.is_dir():
                folder_info = scan_folder(item)
                all_folders.append(folder_info)
                total_files += folder_info.count
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Erreur lors du scan des dossiers: {str(e)}"
        )
    
    # Trier avec "En attente" en premier, puis alphab√©tique
    def sort_key(folder: FolderItem) -> tuple:
        if folder.name == "En attente":
            return (0, folder.name)  # En premier
        return (1, folder.name)  # Puis alphab√©tique
    
    all_folders.sort(key=sort_key)
    
    # Limiter √† 7 dossiers max selon les specs
    if len(all_folders) > 7:
        all_folders = all_folders[:7]
    
    return OCRFolderStructureResponse(
        folders=all_folders,
        total_files=total_files
    )


@router.get("/{document_id}", response_model=DocumentResponse)
async def get_document(
    document_id: int,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """R√©cup√®re un document sp√©cifique"""
    result = await db.execute(
        select(Document).where(
            Document.id == document_id,
            Document.user_id == current_user.id
        )
    )
    document = result.scalar_one_or_none()
    
    if not document:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Document not found"
        )
    
    return document


@router.post("/upload", response_model=DocumentResponse)
async def upload_document(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """Upload d'un nouveau document avec traitement OCR automatique"""
    import os
    from datetime import datetime
    
    # Create upload directory dans le dossier natif
    upload_dir = "/Users/stephaneansel/Documents/LEXO_v1/OCR/En attente"
    os.makedirs(upload_dir, exist_ok=True)
    
    # Save file directement dans le dossier surveill√©
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    safe_filename = f"{timestamp}_{file.filename}"
    file_path = os.path.join(upload_dir, safe_filename)
    
    content = await file.read()
    with open(file_path, "wb") as f:
        f.write(content)
    
    # Create document entry temporaire (sera mis √† jour par le traitement OCR)
    document = Document(
        filename=file.filename,
        original_filename=file.filename,
        file_path=file_path,
        file_size=len(content),
        mime_type=file.content_type or "application/octet-stream",
        user_id=current_user.id,
        category="non_classe",  # Sera mis √† jour par le traitement
        confidence_score=0.0,
        ocr_text="",
        entities=[],
        custom_tags=[],
        processed_at=None  # Indique qu'il n'est pas encore trait√©
    )
    
    db.add(document)
    await db.commit()
    await db.refresh(document)
    
    # Lancer le traitement OCR en arri√®re-plan
    background_tasks.add_task(
        process_uploaded_document,
        file_path,
        document.id,
        current_user.id
    )
    
    return document


async def process_uploaded_document(file_path: str, document_id: int, user_id: int):
    """Traite un document upload√© avec OCR, Mistral et classification automatique"""
    import logging
    import httpx
    import time
    from datetime import datetime
    import tempfile
    from pdf2image import convert_from_path
    
    logger = logging.getLogger(__name__)
    logger.info(f"üîÑ D√©but traitement document upload√©: {Path(file_path).name}")
    
    start_time = time.time()
    
    try:
        # 1. Analyse pr√©liminaire avec Mistral MLX (bas√©e sur le nom du fichier)
        filename = Path(file_path).name
        logger.info(f"ü§ñ √âtape 1: Pr√©-analyse Mistral du fichier: {filename}")
        
        mistral_preanalysis = None
        mistral_category_suggestion = None
        
        try:
            # Analyse bas√©e sur le nom de fichier et le type de document
            mistral_preanalysis = await _get_mistral_filename_analysis(filename)
            if mistral_preanalysis and mistral_preanalysis.get('success'):
                result_data = mistral_preanalysis.get('result', {})
                mistral_category_suggestion = result_data.get('document_type')
                logger.info(f"üéØ Pr√©-analyse Mistral: type={mistral_category_suggestion}")
        except Exception as e:
            logger.warning(f"Pr√©-analyse Mistral √©chou√©e: {e}")
        
        # 2. Pr√©paration du fichier pour OCR
        processing_path = str(file_path)
        temp_image_path = None
        
        # Conversion PDF vers image si n√©cessaire
        if Path(file_path).suffix.lower() == '.pdf':
            try:
                with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_file:
                    temp_image_path = temp_file.name
                
                images = convert_from_path(str(file_path), first_page=1, last_page=1)
                if images:
                    images[0].save(temp_image_path, 'PNG')
                    processing_path = temp_image_path
                    logger.info(f"üìÑ PDF converti en image: {temp_image_path}")
                else:
                    logger.error(f"√âchec conversion PDF: {Path(file_path).name}")
                    return
                    
            except Exception as e:
                logger.error(f"Erreur conversion PDF {Path(file_path).name}: {e}")
                return
        
        # 3. Traitement OCR avec le moteur hybride
        from ocr.hybrid_ocr import HybridOCREngine, OCRStrategy
        from ocr.entity_extractor import EntityExtractor
        
        try:
            # OCR hybride (TrOCR + Tesseract fallback)
            ocr_engine = HybridOCREngine()
            ocr_result = ocr_engine.extract_text(
                processing_path,
                strategy=OCRStrategy.TROCR_FALLBACK
            )
            
            # Extraction d'entit√©s
            entity_extractor = EntityExtractor()
            entities = []
            if hasattr(ocr_result, 'text') and ocr_result.text:
                try:
                    entity_result = entity_extractor.extract_entities(ocr_result.text)
                    entities = [
                        {
                            "type": entity.entity_type,
                            "value": entity.value,
                            "confidence": entity.confidence
                        }
                        for entity in entity_result.entities
                    ]
                except Exception as e:
                    logger.warning(f"Extraction d'entit√©s √©chou√©e: {e}")
            
            logger.info(f"üîç OCR termin√©: {getattr(ocr_result, 'word_count', 0)} mots, confiance: {getattr(ocr_result, 'confidence', 0):.2f}")
            
        finally:
            # Nettoyer le fichier temporaire
            if temp_image_path and Path(temp_image_path).exists():
                Path(temp_image_path).unlink()
                logger.debug(f"Fichier temporaire supprim√©: {temp_image_path}")
        
        # 4. Analyse avanc√©e post-OCR avec Mistral MLX (service natif)
        ocr_text = getattr(ocr_result, 'text', str(ocr_result))
        mistral_analysis = None
        
        if ocr_text and len(ocr_text.strip()) > 50:
            try:
                mistral_analysis = await _get_mistral_analysis(ocr_text)
                if mistral_analysis and mistral_analysis.get('success'):
                    result_data = mistral_analysis.get('result', {})
                    # Fusionner avec la pr√©-analyse si elle existe
                    if not mistral_category_suggestion:
                        mistral_category_suggestion = result_data.get('document_type')
                    logger.info(f"ü§ñ Analyse Mistral post-OCR: type={mistral_category_suggestion}, confiance={result_data.get('confidence', 0)}")
            except Exception as e:
                logger.warning(f"Analyse Mistral post-OCR √©chou√©e: {e}")
        
        # 5. Classification hybride (r√®gles + Mistral + pr√©-analyse)
        from services.document_classifier import get_document_classifier
        
        classifier = get_document_classifier()
        classification_result = classifier.classify_document(
            filename=Path(file_path).name,
            ocr_text=ocr_text,
            entities=entities
        )
        
        # Affiner la classification avec l'analyse Mistral
        final_category = classification_result.category
        final_confidence = classification_result.confidence
        
        if mistral_category_suggestion and mistral_analysis:
            mistral_confidence = mistral_analysis.get('result', {}).get('confidence', 0)
            # Mapping des types Mistral vers nos cat√©gories
            mistral_to_our_categories = {
                'facture': 'factures',
                'rib': 'rib', 
                'contrat': 'contrats',
                'attestation': 'attestations',
                'courrier': 'courriers',
                'rapport': 'non_classes',
                'autre': 'non_classes'
            }
            
            mistral_mapped_category = mistral_to_our_categories.get(mistral_category_suggestion, 'non_classes')
            
            # Si Mistral est tr√®s confiant et diff√©rent, privil√©gier Mistral
            if mistral_confidence > 0.8 and mistral_mapped_category != final_category:
                logger.info(f"üîÑ Classification ajust√©e: {final_category} ‚Üí {mistral_mapped_category} (Mistral confiance: {mistral_confidence:.2f})")
                final_category = mistral_mapped_category
                final_confidence = min(0.95, (final_confidence + mistral_confidence) / 2)
            # Si m√™me cat√©gorie, booster la confiance
            elif mistral_mapped_category == final_category:
                final_confidence = min(0.98, final_confidence * 1.2)
        
        # 6. G√©n√©ration de r√©sum√© Mistral
        summary = ""
        if mistral_analysis and mistral_analysis.get('success'):
            result_data = mistral_analysis.get('result', {})
            summary = result_data.get('summary', '').strip()
            
            if not summary or len(summary) < 10:
                try:
                    summary = await _generate_mistral_summary(ocr_text, final_category)
                except Exception as e:
                    logger.warning(f"G√©n√©ration r√©sum√© Mistral √©chou√©e: {e}")
                    summary = f"Document de type {final_category} analys√©. Contenu de {len(ocr_text.split())} mots trait√© automatiquement."
        else:
            try:
                summary = await _generate_mistral_summary(ocr_text, final_category)
            except Exception as e:
                logger.warning(f"G√©n√©ration r√©sum√© Mistral √©chou√©e: {e}")
                summary = f"Document de type {final_category} analys√©. Contenu de {len(ocr_text.split())} mots trait√© automatiquement."
        
        # 7. Mise √† jour du document en base
        from core.database import AsyncSessionLocal
        async with AsyncSessionLocal() as db:
            result = await db.execute(
                select(Document).where(Document.id == document_id)
            )
            document = result.scalar_one_or_none()
            
            if document:
                # Mettre √† jour le document existant
                document.category = final_category
                document.confidence_score = final_confidence
                document.ocr_text = ocr_text[:10000]  # Limiter la taille
                document.entities = entities
                document.custom_tags = [final_category]
                document.summary = summary
                document.processed_at = datetime.utcnow()
                
                await db.commit()
                
                process_time = time.time() - start_time
                
                logger.info(f"‚úÖ Document mis √† jour et trait√©: {Path(file_path).name}")
                logger.info(f"   üìä ID: {document.id} | Cat√©gorie: {final_category}")
                logger.info(f"   üîç Confiance: {document.confidence_score:.2f}")
                logger.info(f"   üìù Texte: {len(document.ocr_text)} chars")
                logger.info(f"   üìÑ R√©sum√©: {len(summary)} chars")
                logger.info(f"   üè∑Ô∏è Entit√©s: {len(entities)} trouv√©es")
                logger.info(f"   ‚è±Ô∏è Temps: {process_time:.2f}s")
                
                # 8. D√©placer le fichier vers le dossier de cat√©gorie et mettre √† jour le chemin
                new_file_path = await _move_to_category_folder(Path(file_path), final_category)
                
                # 9. Mettre √† jour le chemin du fichier en base
                document.file_path = new_file_path
                await db.commit()
                
            else:
                logger.error(f"Document {document_id} non trouv√© en base")
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du traitement {Path(file_path).name}: {e}")
        import traceback
        traceback.print_exc()


async def _get_mistral_analysis(text: str) -> dict:
    """Obtient l'analyse compl√®te du document depuis Mistral MLX natif avec cache"""
    from utils.mistral_cache import cached_mistral_analysis
    
    async def _do_mistral_request(text_excerpt: str, analysis_types: list) -> dict:
        """Fonction interne pour faire l'appel Mistral"""
        try:
            import httpx
            import os
            
            # Appel √† l'API Mistral locale (service document_analyzer)
            mistral_host = "localhost"  # Architecture native macOS
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(
                    f"http://{mistral_host}:8004/analyze",
                    json={
                        "text": text_excerpt,
                        "analysis_types": analysis_types
                    }
                )
                
                if response.status_code == 200:
                    return response.json()
                else:
                    logger.warning(f"Erreur API Mistral: {response.status_code}")
                    return {"success": False, "error": f"HTTP {response.status_code}"}
                    
        except Exception as e:
            logger.warning(f"Erreur connexion Mistral: {e}")
            return {"success": False, "error": str(e)}
    
    # Limiter le texte pour √©viter les prompts trop longs
    text_excerpt = text[:2000] if len(text) > 2000 else text
    analysis_types = ["classification", "summarization", "key_extraction"]
    
    # Utiliser le cache intelligent
    return await cached_mistral_analysis(
        text_excerpt, 
        analysis_types, 
        lambda t, at: _do_mistral_request(t, at)
    )


async def _generate_mistral_summary(text: str, category: str) -> str:
    """G√©n√®re un r√©sum√© du document avec Mistral MLX"""
    try:
        import httpx
        import os
        
        # Pr√©parer le prompt selon la cat√©gorie
        category_prompts = {
            'factures': "R√©sume cette facture en mentionnant : le fournisseur, le montant total, la date, et les services/produits principaux.",
            'attestations': "R√©sume cette attestation en mentionnant : l'organisme √©metteur, la personne concern√©e, la validit√© et l'objet de l'attestation.",
            'rib': "R√©sume ce RIB en mentionnant : la banque, le titulaire du compte, et les informations bancaires essentielles.",
            'impots': "R√©sume ce document fiscal en mentionnant : le type de document, l'ann√©e concern√©e, les montants principaux.",
            'courriers': "R√©sume ce courrier en mentionnant : l'exp√©diteur, le destinataire, le sujet principal et les actions requises.",
            'non_classes': "Fais un r√©sum√© concis de ce document en mentionnant les informations les plus importantes."
        }
        
        prompt = category_prompts.get(category, category_prompts['non_classes'])
        
        # Limiter le texte pour √©viter les prompts trop longs
        text_excerpt = text[:2000] if len(text) > 2000 else text
        
        # Appel √† l'API Mistral locale (service document_analyzer)
        mistral_host = "localhost"  # Architecture native macOS
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(
                f"http://{mistral_host}:8004/analyze",
                json={
                    "text": text_excerpt,
                    "analysis_types": ["summarization"]
                }
            )
            
            if response.status_code == 200:
                result = response.json()
                if result.get('success'):
                    summary = result.get('result', {}).get('summary', '').strip()
                    if summary and len(summary) > 10:
                        return summary[:500]  # Limiter la taille
            
            # Fallback si Mistral n'est pas disponible
            logger.info(f"Mistral indisponible, g√©n√©ration r√©sum√© basique pour {category}")
            return f"Document de type {category} analys√© - {len(text.split())} mots de contenu."
            
    except Exception as e:
        logger.warning(f"Erreur g√©n√©ration r√©sum√© Mistral: {e}")
        return f"Document {category} de {len(text.split())} mots analys√© automatiquement."


async def _move_to_category_folder(file_path: Path, category: str) -> str:
    """D√©place le fichier vers le dossier de cat√©gorie appropri√© et retourne le nouveau chemin"""
    logger = logging.getLogger(__name__)
    try:
        # Base directory pour la structure OCR native
        base_ocr_dir = Path("/Users/stephaneansel/Documents/LEXO_v1/OCR")
        
        # Mapping des cat√©gories vers les dossiers existants
        category_mapping = {
            'factures': 'factures',
            'attestations': 'attestations', 
            'rib': 'rib',
            'contrats': 'contrats',
            'impots': 'impots',
            'courriers': 'courriers',  # Dossier courriers maintenant disponible
            'cartes_transport': 'non_classes',  # Pas de dossier cartes_transport
            'documents_personnels': 'non_classes',  # Pas de dossier documents_personnels 
            'non_classes': 'non_classes'
        }
        
        # D√©terminer le dossier de destination
        target_folder_name = category_mapping.get(category, 'non_classes')
        category_folder = base_ocr_dir / target_folder_name
        
        # Cr√©er le dossier s'il n'existe pas (normalement ils existent d√©j√†)
        category_folder.mkdir(exist_ok=True)
        
        # Destination finale
        destination = category_folder / file_path.name
        
        # √âviter les conflits de noms
        counter = 1
        original_destination = destination
        while destination.exists():
            stem = original_destination.stem
            suffix = original_destination.suffix
            destination = category_folder / f"{stem}_{counter}{suffix}"
            counter += 1
        
        # D√©placer le fichier
        file_path.rename(destination)
        logger.info(f"üìÅ Fichier d√©plac√© vers: OCR/{target_folder_name}/{destination.name}")
        
        return str(destination)
        
    except Exception as e:
        logger.warning(f"√âchec du d√©placement vers {category}: {e}")
        # Retourner le chemin original en cas d'√©chec
        return str(file_path)


async def _get_mistral_filename_analysis(filename: str) -> dict:
    """Analyse pr√©liminaire du document bas√©e sur le nom de fichier"""
    try:
        import httpx
        import os
        
        # Pr√©parer un prompt sp√©cialis√© pour l'analyse du nom de fichier
        prompt = f"""Analyse ce nom de fichier et d√©termine le type de document probable : "{filename}"
        
Types possibles : factures, rib, contrats, attestations, courriers, rapports, cartes_transport, documents_personnels, non_classes

R√©ponds en JSON avec :
- document_type: le type le plus probable
- confidence: score de confiance (0-1)
- reasoning: courte explication"""
        
        mistral_host = "localhost"  # Architecture native macOS
        async with httpx.AsyncClient(timeout=10.0) as client:
            response = await client.post(
                f"http://{mistral_host}:8004/analyze",
                json={
                    "text": prompt,
                    "analysis_types": ["classification"]
                }
            )
            
            if response.status_code == 200:
                return response.json()
            else:
                logger.warning(f"Erreur API Mistral filename: {response.status_code}")
                return {"success": False, "error": f"HTTP {response.status_code}"}
                
    except Exception as e:
        logger.warning(f"Erreur pr√©-analyse Mistral filename: {e}")
        return {"success": False, "error": str(e)}


@router.post("/upload-and-process", response_model=DocumentResponse)
async def upload_and_process_document(
    file: UploadFile = File(...),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    Upload et traitement complet d'un document (pipeline unifi√©)
    - Upload du fichier
    - OCR extraction de texte
    - Analyse Mistral MLX pour classification et r√©sum√©
    - Sauvegarde avec toutes les m√©tadonn√©es
    """
    import os
    import time
    import tempfile
    from datetime import datetime
    from pathlib import Path
    from pdf2image import convert_from_path
    
    logger = logging.getLogger(__name__)
    logger.info(f"üöÄ Pipeline unifi√© d√©marr√© pour: {file.filename}")
    
    start_time = time.time()
    
    try:
        # 1. Validation du fichier
        if not file.filename:
            raise HTTPException(status_code=400, detail="Nom de fichier manquant")
        
        file_extension = Path(file.filename).suffix.lower()
        if file_extension not in {'.pdf', '.png', '.jpg', '.jpeg', '.tiff', '.bmp'}:
            raise HTTPException(
                status_code=400, 
                detail=f"Format non support√©: {file_extension}"
            )
        
        # 2. Sauvegarde temporaire du fichier
        with tempfile.NamedTemporaryFile(suffix=file_extension, delete=False) as tmp_file:
            content = await file.read()
            tmp_file.write(content)
            temp_file_path = tmp_file.name
        
        try:
            # 3. Pr√©paration pour OCR (conversion PDF ‚Üí Image si n√©cessaire)
            processing_path = temp_file_path
            temp_image_path = None
            
            if file_extension == '.pdf':
                try:
                    with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_img:
                        temp_image_path = temp_img.name
                    
                    images = convert_from_path(temp_file_path, first_page=1, last_page=1)
                    if images:
                        images[0].save(temp_image_path, 'PNG')
                        processing_path = temp_image_path
                        logger.info(f"üìÑ PDF converti en image")
                    else:
                        raise HTTPException(status_code=500, detail="√âchec conversion PDF")
                        
                except Exception as e:
                    logger.error(f"Erreur conversion PDF: {e}")
                    raise HTTPException(status_code=500, detail=f"Erreur conversion PDF: {str(e)}")
            
            # 4. OCR avec Tesseract (fallback fiable)
            logger.info("üîç D√©marrage OCR Tesseract...")
            from ocr.tesseract_ocr import TesseractOCR
            from ocr.entity_extractor import EntityExtractor
            
            ocr_engine = TesseractOCR()
            ocr_result = ocr_engine.extract_text(processing_path)
            
            ocr_text = getattr(ocr_result, 'text', str(ocr_result))
            ocr_confidence = getattr(ocr_result, 'confidence', 0.0)
            word_count = getattr(ocr_result, 'word_count', len(ocr_text.split()))
            
            logger.info(f"‚úÖ OCR termin√©: {word_count} mots, confiance: {ocr_confidence:.2f}")
            
            # 5. Extraction d'entit√©s
            entity_extractor = EntityExtractor()
            entities_data = []
            
            if ocr_text:
                try:
                    entity_result = entity_extractor.extract_entities(ocr_text)
                    entities_data = [
                        f"{entity.entity_type}:{entity.value}" 
                        for entity in entity_result.entities[:10]  # Limiter √† 10
                    ]
                    logger.info(f"üè∑Ô∏è Entit√©s extraites: {len(entities_data)}")
                except Exception as e:
                    logger.warning(f"Extraction entit√©s √©chou√©e: {e}")
            
            # 6. Analyse Mistral MLX pour classification et r√©sum√©
            mistral_analysis = None
            mistral_category = None
            summary = ""
            
            if ocr_text and len(ocr_text.strip()) > 50:
                try:
                    mistral_analysis = await _call_mistral_analysis(ocr_text)
                    if mistral_analysis.get('success'):
                        result_data = mistral_analysis.get('result', {})
                        mistral_category = result_data.get('document_type')
                        summary = result_data.get('summary', '').strip()
                        
                        logger.info(f"ü§ñ Mistral: type={mistral_category}, r√©sum√©={len(summary)} chars")
                    else:
                        logger.warning(f"Mistral √©chec: {mistral_analysis.get('error', 'Erreur inconnue')}")
                        
                except Exception as e:
                    logger.warning(f"Analyse Mistral √©chou√©e: {e}")
            
            # 7. Classification unifi√©e avec architecture Mistral-centr√©e
            from services.document_classifier import get_document_classifier
            
            classifier = get_document_classifier()
            classification_result = classifier.classify_document(
                filename=file.filename,
                ocr_text=ocr_text,
                entities=entities_data
            )
            
            final_category = classification_result.category
            final_confidence = classification_result.confidence
            
            logger.info(f"üéØ Classification finale: {final_category} (conf: {final_confidence:.2f})")
            logger.info(f"ü§ñ Source d√©cision: {classification_result.decision_source}")
            logger.info(f"ü§ñ Mistral pr√©diction: {classification_result.mistral_prediction} (conf: {classification_result.mistral_confidence:.2f})")
            
            # 8. G√©n√©ration de r√©sum√© si manquant
            if not summary:
                summary = f"Document de type {final_category} analys√© automatiquement. Contenu: {word_count} mots extraits avec {final_confidence:.1%} de confiance."
            
            # 9. D√©placer le fichier vers le dossier de cat√©gorie
            final_file_path = await _move_to_category_folder(Path(temp_file_path), final_category)
            
            # 10. Sauvegarde en base de donn√©es avec le bon chemin
            document = Document(
                filename=file.filename,
                original_filename=file.filename,
                file_path=final_file_path,  # Chemin final dans le dossier de cat√©gorie
                file_size=len(content),
                mime_type=file.content_type or "application/octet-stream",
                user_id=current_user.id,
                category=final_category,
                confidence_score=final_confidence,
                ocr_text=ocr_text[:10000],  # Limiter la taille
                entities=entities_data,
                custom_tags=[final_category],
                summary=summary[:500],  # Limiter la taille
                processed_at=datetime.utcnow()
            )
            
            db.add(document)
            await db.commit()
            await db.refresh(document)
            
            # 11. M√©triques finales
            total_time = time.time() - start_time
            
            logger.info(f"‚úÖ Pipeline unifi√© termin√© avec succ√®s:")
            logger.info(f"   üìä Document ID: {document.id}")
            logger.info(f"   üè∑Ô∏è Cat√©gorie: {final_category} (confiance: {final_confidence:.2f})")
            logger.info(f"   üìù Texte: {len(ocr_text)} chars, {word_count} mots")
            logger.info(f"   üìÑ R√©sum√©: {len(summary)} chars")
            logger.info(f"   üîç Entit√©s: {len(entities_data)}")
            logger.info(f"   üìÅ Fichier: {final_file_path}")
            logger.info(f"   ‚è±Ô∏è Temps total: {total_time:.2f}s")
            
            return document
            
        finally:
            # Nettoyage uniquement des fichiers temporaires de conversion (pas le fichier principal)
            if temp_image_path and os.path.exists(temp_image_path):
                try:
                    os.unlink(temp_image_path)
                    logger.debug(f"Fichier temporaire de conversion supprim√©: {temp_image_path}")
                except Exception as e:
                    logger.warning(f"√âchec suppression fichier temporaire {temp_image_path}: {e}")
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erreur pipeline unifi√© {file.filename}: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Erreur traitement: {str(e)}")


async def _call_mistral_analysis(text: str) -> dict:
    """Appel au service Mistral MLX natif avec gestion d'erreur robuste"""
    logger = logging.getLogger(__name__)
    try:
        import httpx
        import os
        
        # Configuration service MLX
        mistral_host = "localhost"  # Architecture native macOS
        
        # Limiter le texte pour √©viter les timeouts
        text_excerpt = text[:2000] if len(text) > 2000 else text
        
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(
                f"http://{mistral_host}:8004/analyze",
                json={
                    "text": text_excerpt,
                    "analysis_types": ["classification", "summarization", "key_extraction"]
                }
            )
            
            if response.status_code == 200:
                return response.json()
            else:
                logger.warning(f"Erreur API Mistral: {response.status_code}")
                return {"success": False, "error": f"HTTP {response.status_code}"}
                
    except Exception as e:
        logger.warning(f"Erreur connexion Mistral: {e}")
        return {"success": False, "error": str(e)}


@router.delete("/{document_id}")
async def delete_document(
    document_id: int,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """Supprime un document"""
    result = await db.execute(
        select(Document).where(
            Document.id == document_id,
            Document.user_id == current_user.id
        )
    )
    document = result.scalar_one_or_none()
    
    if not document:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Document not found"
        )
    
    await db.delete(document)
    await db.commit()
    
    return {"message": "Document deleted successfully"}