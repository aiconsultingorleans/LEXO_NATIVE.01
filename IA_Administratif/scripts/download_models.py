#!/usr/bin/env python3
"""
Script de pr√©-t√©l√©chargement des mod√®les ML pour LEXO v1
T√©l√©charge tous les mod√®les n√©cessaires dans le cache local
Usage: python download_models.py [--cache-dir /path/to/cache]
"""

import os
import sys
import argparse
import logging
from pathlib import Path
from typing import Dict, List, Optional
import time

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# D√©finition des mod√®les √† t√©l√©charger
MODELS_CONFIG = {
    "transformers": [
        {
            "name": "microsoft/trocr-base-printed",
            "type": "TrOCR",
            "size": "558MB",
            "description": "OCR pour texte imprim√©"
        },
        {
            "name": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2", 
            "type": "Embeddings",
            "size": "120MB",
            "description": "Embeddings multilingues"
        }
    ],
    "spacy": [
        {
            "name": "fr_core_news_sm",
            "type": "spaCy",
            "size": "15MB", 
            "description": "Mod√®le fran√ßais pour NER"
        }
    ],
    "mlx": [
        {
            "name": "mlx-community/Mistral-7B-Instruct-v0.3-4bit",
            "type": "MLX LLM",
            "size": "2.1GB",
            "description": "Mod√®le Mistral quantifi√© pour MLX"
        }
    ]
}


class ModelDownloader:
    """Gestionnaire de t√©l√©chargement des mod√®les"""
    
    def __init__(self, cache_dir: Optional[str] = None):
        """
        Initialise le t√©l√©chargeur
        
        Args:
            cache_dir: R√©pertoire de cache personnalis√©
        """
        # D√©terminer le r√©pertoire de cache
        if cache_dir:
            self.base_cache_dir = Path(cache_dir)
        else:
            # Utiliser le r√©pertoire ml_models du projet
            project_root = Path(__file__).parent.parent
            self.base_cache_dir = project_root / "ml_models"
        
        # Cr√©er les sous-r√©pertoires
        self.transformers_cache = self.base_cache_dir / "transformers"
        self.spacy_cache = self.base_cache_dir / "spacy"
        self.mlx_cache = self.base_cache_dir / "mistral_7b_mlx"
        
        # Cr√©er les r√©pertoires
        for cache_dir in [self.transformers_cache, self.spacy_cache, self.mlx_cache]:
            cache_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"Cache de base configur√©: {self.base_cache_dir}")
    
    def download_transformers_models(self) -> bool:
        """T√©l√©charge les mod√®les HuggingFace Transformers"""
        logger.info("üì• T√©l√©chargement des mod√®les Transformers...")
        
        try:
            from transformers import (
                TrOCRProcessor, 
                VisionEncoderDecoderModel,
                AutoTokenizer,
                AutoModel
            )
            
            # Configurer le cache HuggingFace
            os.environ['TRANSFORMERS_CACHE'] = str(self.transformers_cache)
            
            success_count = 0
            
            for model_config in MODELS_CONFIG["transformers"]:
                model_name = model_config["name"]
                logger.info(f"  ‚¨áÔ∏è  {model_config['description']} ({model_config['size']})")
                logger.info(f"      {model_name}")
                
                try:
                    start_time = time.time()
                    
                    if "trocr" in model_name.lower():
                        # Mod√®le TrOCR sp√©cifique
                        processor = TrOCRProcessor.from_pretrained(
                            model_name, 
                            cache_dir=self.transformers_cache
                        )
                        model = VisionEncoderDecoderModel.from_pretrained(
                            model_name,
                            cache_dir=self.transformers_cache
                        )
                        logger.info(f"      ‚úÖ TrOCR t√©l√©charg√© en {time.time() - start_time:.1f}s")
                        
                    elif "sentence-transformers" in model_name:
                        # Mod√®le d'embeddings
                        try:
                            from sentence_transformers import SentenceTransformer
                            model = SentenceTransformer(
                                model_name,
                                cache_folder=str(self.transformers_cache)
                            )
                            logger.info(f"      ‚úÖ Embeddings t√©l√©charg√© en {time.time() - start_time:.1f}s")
                        except ImportError:
                            logger.warning("      sentence-transformers non install√©, utilisation d'AutoModel")
                            tokenizer = AutoTokenizer.from_pretrained(
                                model_name,
                                cache_dir=self.transformers_cache
                            )
                            model = AutoModel.from_pretrained(
                                model_name,
                                cache_dir=self.transformers_cache
                            )
                            logger.info(f"      ‚úÖ Mod√®le t√©l√©charg√© en {time.time() - start_time:.1f}s")
                    
                    success_count += 1
                    
                except Exception as e:
                    logger.error(f"      ‚ùå Erreur: {e}")
                    continue
            
            logger.info(f"‚úÖ Transformers: {success_count}/{len(MODELS_CONFIG['transformers'])} mod√®les t√©l√©charg√©s")
            return success_count > 0
            
        except ImportError as e:
            logger.error(f"‚ùå Transformers non disponible: {e}")
            return False
    
    def download_spacy_models(self) -> bool:
        """T√©l√©charge les mod√®les spaCy"""
        logger.info("üì• T√©l√©chargement des mod√®les spaCy...")
        
        try:
            import spacy
            from spacy.cli import download
            import subprocess
            
            # Configurer le r√©pertoire spaCy
            os.environ['SPACY_DATA'] = str(self.spacy_cache)
            
            success_count = 0
            
            for model_config in MODELS_CONFIG["spacy"]:
                model_name = model_config["name"]
                logger.info(f"  ‚¨áÔ∏è  {model_config['description']} ({model_config['size']})")
                logger.info(f"      {model_name}")
                
                try:
                    start_time = time.time()
                    
                    # V√©rifier si le mod√®le est d√©j√† install√©
                    try:
                        nlp = spacy.load(model_name)
                        logger.info(f"      ‚úÖ D√©j√† install√©")
                        success_count += 1
                        continue
                    except OSError:
                        pass
                    
                    # T√©l√©charger le mod√®le
                    cmd = [sys.executable, "-m", "spacy", "download", model_name]
                    result = subprocess.run(cmd, capture_output=True, text=True)
                    
                    if result.returncode == 0:
                        logger.info(f"      ‚úÖ spaCy t√©l√©charg√© en {time.time() - start_time:.1f}s")
                        success_count += 1
                    else:
                        logger.error(f"      ‚ùå Erreur spaCy: {result.stderr}")
                
                except Exception as e:
                    logger.error(f"      ‚ùå Erreur: {e}")
                    continue
            
            logger.info(f"‚úÖ spaCy: {success_count}/{len(MODELS_CONFIG['spacy'])} mod√®les t√©l√©charg√©s")
            return success_count > 0
            
        except ImportError as e:
            logger.error(f"‚ùå spaCy non disponible: {e}")
            return False
    
    def download_mlx_models(self) -> bool:
        """T√©l√©charge les mod√®les MLX"""
        logger.info("üì• T√©l√©chargement des mod√®les MLX...")
        
        try:
            # MLX n√©cessite import sp√©cifique
            try:
                import mlx
                import mlx.core as mx
                from mlx_lm import load
            except ImportError:
                logger.warning("‚ùå MLX non disponible (normal sur non-Apple Silicon)")
                return False
            
            success_count = 0
            
            for model_config in MODELS_CONFIG["mlx"]:
                model_name = model_config["name"]
                logger.info(f"  ‚¨áÔ∏è  {model_config['description']} ({model_config['size']})")
                logger.info(f"      {model_name}")
                
                try:
                    start_time = time.time()
                    
                    # Utiliser mlx_lm pour t√©l√©charger
                    model_path = self.mlx_cache / model_name.replace("/", "_")
                    
                    # T√©l√©charger le mod√®le MLX
                    model, tokenizer = load(model_name, model_path=str(model_path))
                    
                    logger.info(f"      ‚úÖ MLX t√©l√©charg√© en {time.time() - start_time:.1f}s")
                    success_count += 1
                
                except Exception as e:
                    logger.error(f"      ‚ùå Erreur MLX: {e}")
                    continue
            
            logger.info(f"‚úÖ MLX: {success_count}/{len(MODELS_CONFIG['mlx'])} mod√®les t√©l√©charg√©s")
            return success_count > 0
            
        except ImportError as e:
            logger.error(f"‚ùå MLX non disponible: {e}")
            return False
    
    def check_cache_sizes(self):
        """Affiche les tailles des caches"""
        logger.info("üìä Tailles des caches:")
        
        def get_dir_size(path: Path) -> float:
            """Calcule la taille d'un r√©pertoire en MB"""
            if not path.exists():
                return 0.0
            
            total_size = 0
            for file_path in path.rglob('*'):
                if file_path.is_file():
                    total_size += file_path.stat().st_size
            
            return total_size / (1024 * 1024)  # Convertir en MB
        
        caches = {
            "Transformers": self.transformers_cache,
            "spaCy": self.spacy_cache, 
            "MLX": self.mlx_cache
        }
        
        total_size = 0
        for cache_name, cache_path in caches.items():
            size_mb = get_dir_size(cache_path)
            total_size += size_mb
            logger.info(f"  {cache_name}: {size_mb:.1f} MB ({cache_path})")
        
        logger.info(f"  Total: {total_size:.1f} MB")
    
    def download_all(self) -> bool:
        """T√©l√©charge tous les mod√®les"""
        logger.info("üöÄ D√©but du t√©l√©chargement de tous les mod√®les LEXO v1")
        logger.info(f"üìÅ Cache de base: {self.base_cache_dir}")
        
        start_time = time.time()
        results = []
        
        # T√©l√©charger chaque type de mod√®le
        results.append(self.download_transformers_models())
        results.append(self.download_spacy_models())
        results.append(self.download_mlx_models())
        
        # V√©rifier les tailles
        self.check_cache_sizes()
        
        total_time = time.time() - start_time
        success_count = sum(results)
        
        logger.info(f"üéâ T√©l√©chargement termin√© en {total_time:.1f}s")
        logger.info(f"‚úÖ {success_count}/3 types de mod√®les t√©l√©charg√©s avec succ√®s")
        
        if success_count >= 2:  # Au moins Transformers + spaCy
            logger.info("üéØ Configuration minimale atteinte pour LEXO v1")
            return True
        else:
            logger.warning("‚ö†Ô∏è  Configuration incompl√®te, certaines fonctionnalit√©s seront limit√©es")
            return False


def main():
    """Point d'entr√©e principal"""
    parser = argparse.ArgumentParser(
        description="T√©l√©charge tous les mod√®les ML pour LEXO v1"
    )
    parser.add_argument(
        "--cache-dir",
        type=str,
        help="R√©pertoire de cache personnalis√© (d√©faut: ./ml_models)"
    )
    parser.add_argument(
        "--check-only",
        action="store_true",
        help="V√©rifier les caches existants sans t√©l√©charger"
    )
    parser.add_argument(
        "--models",
        nargs="+",
        choices=["transformers", "spacy", "mlx"],
        help="Types de mod√®les √† t√©l√©charger (d√©faut: tous)"
    )
    
    args = parser.parse_args()
    
    # Cr√©er le downloader
    downloader = ModelDownloader(args.cache_dir)
    
    if args.check_only:
        # V√©rification seulement
        downloader.check_cache_sizes()
        return 0
    
    # T√©l√©chargement
    if args.models:
        # T√©l√©chargement s√©lectif
        results = []
        if "transformers" in args.models:
            results.append(downloader.download_transformers_models())
        if "spacy" in args.models:
            results.append(downloader.download_spacy_models())
        if "mlx" in args.models:
            results.append(downloader.download_mlx_models())
        
        success = any(results)
    else:
        # T√©l√©chargement complet
        success = downloader.download_all()
    
    return 0 if success else 1


if __name__ == "__main__":
    sys.exit(main())