"""
Cache intelligent pour les analyses Mistral
√âvite les appels r√©p√©titifs √† l'API MLX pour les m√™mes contenus
"""

import hashlib
import json
import time
from typing import Dict, Any, Optional
from pathlib import Path
import logging

logger = logging.getLogger(__name__)

class MistralCache:
    """Cache en m√©moire pour les analyses Mistral"""
    
    def __init__(self, ttl_seconds: int = 3600):
        """
        Args:
            ttl_seconds: Dur√©e de vie du cache en secondes (par d√©faut 1h)
        """
        self.cache: Dict[str, Dict[str, Any]] = {}
        self.ttl_seconds = ttl_seconds
        
    def _get_cache_key(self, text: str, analysis_types: list) -> str:
        """G√©n√®re une cl√© de cache bas√©e sur le contenu et le type d'analyse"""
        # Nettoyer et normaliser le texte
        clean_text = text.strip().lower()[:1000]  # Prendre les 1000 premiers caract√®res
        
        # Cr√©er une signature unique
        content = f"{clean_text}:{','.join(sorted(analysis_types))}"
        return hashlib.md5(content.encode()).hexdigest()
    
    def get(self, text: str, analysis_types: list) -> Optional[Dict[str, Any]]:
        """R√©cup√®re un r√©sultat depuis le cache"""
        cache_key = self._get_cache_key(text, analysis_types)
        
        if cache_key in self.cache:
            entry = self.cache[cache_key]
            
            # V√©rifier l'expiration
            if time.time() - entry['timestamp'] < self.ttl_seconds:
                logger.info(f"üéØ Cache hit for Mistral analysis: {cache_key[:8]}...")
                return entry['data']
            else:
                # Supprimer l'entr√©e expir√©e
                del self.cache[cache_key]
                logger.info(f"‚è∞ Cache expired for: {cache_key[:8]}...")
        
        return None
    
    def set(self, text: str, analysis_types: list, data: Dict[str, Any]) -> None:
        """Stocke un r√©sultat dans le cache"""
        cache_key = self._get_cache_key(text, analysis_types)
        
        self.cache[cache_key] = {
            'data': data,
            'timestamp': time.time()
        }
        
        logger.info(f"üíæ Cached Mistral analysis: {cache_key[:8]}... (cache size: {len(self.cache)})")
        
        # Nettoyage p√©riodique
        self._cleanup_expired()
    
    def _cleanup_expired(self) -> None:
        """Nettoie les entr√©es expir√©es du cache"""
        current_time = time.time()
        expired_keys = [
            key for key, entry in self.cache.items()
            if current_time - entry['timestamp'] >= self.ttl_seconds
        ]
        
        for key in expired_keys:
            del self.cache[key]
        
        if expired_keys:
            logger.info(f"üßπ Cleaned {len(expired_keys)} expired cache entries")
    
    def clear(self) -> None:
        """Vide compl√®tement le cache"""
        self.cache.clear()
        logger.info("üóëÔ∏è Mistral cache cleared")
    
    def get_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques du cache"""
        current_time = time.time()
        
        # Compter les entr√©es valides vs expir√©es
        valid_entries = 0
        expired_entries = 0
        
        for entry in self.cache.values():
            if current_time - entry['timestamp'] < self.ttl_seconds:
                valid_entries += 1
            else:
                expired_entries += 1
        
        return {
            'total_entries': len(self.cache),
            'valid_entries': valid_entries,
            'expired_entries': expired_entries,
            'ttl_seconds': self.ttl_seconds,
            'cache_hit_potential': f"{(valid_entries / max(1, len(self.cache))) * 100:.1f}%"
        }


# Instance globale du cache
_mistral_cache: Optional[MistralCache] = None


def get_mistral_cache() -> MistralCache:
    """R√©cup√®re l'instance globale du cache Mistral"""
    global _mistral_cache
    
    if _mistral_cache is None:
        _mistral_cache = MistralCache(ttl_seconds=3600)  # 1 heure par d√©faut
        logger.info("üöÄ Mistral cache initialized")
    
    return _mistral_cache


async def cached_mistral_analysis(
    text: str, 
    analysis_types: list,
    mistral_analysis_func
) -> Dict[str, Any]:
    """
    Wrapper pour les analyses Mistral avec cache intelligent
    
    Args:
        text: Texte √† analyser
        analysis_types: Types d'analyse √† effectuer
        mistral_analysis_func: Fonction d'analyse Mistral (async)
    
    Returns:
        R√©sultat de l'analyse (depuis le cache ou fra√Æchement calcul√©)
    """
    cache = get_mistral_cache()
    
    # Tentative de r√©cup√©ration depuis le cache
    cached_result = cache.get(text, analysis_types)
    if cached_result is not None:
        return cached_result
    
    # Pas en cache, appeler Mistral
    try:
        result = await mistral_analysis_func(text, analysis_types)
        
        # Stocker en cache si succ√®s
        if result.get('success'):
            cache.set(text, analysis_types, result)
        
        return result
        
    except Exception as e:
        logger.error(f"Erreur analyse Mistral cach√©e: {e}")
        return {"success": False, "error": str(e)}