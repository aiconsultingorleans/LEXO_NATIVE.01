#!/usr/bin/env python3
"""
Script de t√©l√©chargement des mod√®les DONUT + CamemBERT pour usage local
Optimis√© Apple Silicon M4 - √âtape 2 Infrastructure
"""

import os
from pathlib import Path
from transformers import AutoTokenizer, AutoModel, DonutProcessor, VisionEncoderDecoderModel
from loguru import logger

# Configuration des chemins
MODELS_DIR = Path(__file__).parent / "models" / "donut"
MODELS_DIR.mkdir(parents=True, exist_ok=True)

# Mod√®les valid√©s √âtape 1
MODELS_CONFIG = {
    "donut": {
        "name": "naver-clova-ix/donut-base-finetuned-cord-v2",
        "local_path": MODELS_DIR / "donut-base-finetuned-cord-v2",
        "size_gb": 2.31,
        "description": "DONUT OCR-free document understanding"
    },
    "camembert": {
        "name": "almanach/camembert-base", 
        "local_path": MODELS_DIR / "camembert-base",
        "size_gb": 1.41,
        "description": "CamemBERT fran√ßais pour classification"
    },
    "camembert_ner": {
        "name": "Jean-Baptiste/camembert-ner",
        "local_path": MODELS_DIR / "camembert-ner", 
        "size_gb": 1.48,
        "description": "NER fran√ßais pour extraction √©metteurs"
    }
}

def download_model(model_key: str, config: dict) -> bool:
    """T√©l√©charge un mod√®le HuggingFace localement"""
    try:
        logger.info(f"üì• T√©l√©chargement {config['description']} ({config['size_gb']:.2f}GB)")
        logger.info(f"   Mod√®le: {config['name']}")
        logger.info(f"   Destination: {config['local_path']}")
        
        if model_key == "donut":
            # DONUT n√©cessite VisionEncoderDecoderModel et DonutProcessor
            processor = DonutProcessor.from_pretrained(config['name'])
            model = VisionEncoderDecoderModel.from_pretrained(config['name'])
            
            processor.save_pretrained(config['local_path'])
            model.save_pretrained(config['local_path'])
            
        else:
            # CamemBERT et variants utilisent AutoModel/AutoTokenizer
            tokenizer = AutoTokenizer.from_pretrained(config['name'])
            model = AutoModel.from_pretrained(config['name'])
            
            tokenizer.save_pretrained(config['local_path'])
            model.save_pretrained(config['local_path'])
        
        logger.success(f"‚úÖ {config['description']} t√©l√©charg√© avec succ√®s")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erreur t√©l√©chargement {config['description']}: {e}")
        return False

def verify_local_models() -> dict:
    """V√©rifie la pr√©sence des mod√®les t√©l√©charg√©s localement"""
    results = {}
    
    for model_key, config in MODELS_CONFIG.items():
        local_path = config['local_path']
        
        # V√©rifier pr√©sence fichiers essentiels
        config_file = local_path / "config.json"
        model_files = list(local_path.glob("*.safetensors")) or list(local_path.glob("pytorch_model.bin"))
        
        if config_file.exists() and model_files:
            size_mb = sum(f.stat().st_size for f in local_path.rglob("*") if f.is_file()) / (1024**2)
            results[model_key] = {
                "status": "OK",
                "path": str(local_path),
                "size_mb": round(size_mb, 1),
                "files_count": len(list(local_path.rglob("*")))
            }
            logger.success(f"‚úÖ {config['description']}: {size_mb:.1f}MB, {len(model_files)} fichiers mod√®le")
        else:
            results[model_key] = {
                "status": "MISSING",
                "path": str(local_path),
                "size_mb": 0,
                "files_count": 0
            }
            logger.warning(f"‚ö†Ô∏è  {config['description']}: Non trouv√© dans {local_path}")
    
    return results

def main():
    """T√©l√©chargement principal des mod√®les DONUT"""
    logger.info("üç© DONUT - T√©l√©chargement mod√®les locaux √âtape 2")
    logger.info(f"üìÅ Dossier destination: {MODELS_DIR}")
    
    # V√©rification √©tat actuel
    logger.info("üîç V√©rification mod√®les existants...")
    current_status = verify_local_models()
    
    total_downloaded = 0
    total_size_gb = 0
    
    # T√©l√©chargement des mod√®les manquants
    for model_key, config in MODELS_CONFIG.items():
        if current_status[model_key]["status"] == "MISSING":
            logger.info(f"\nüì¶ T√©l√©chargement {model_key}...")
            if download_model(model_key, config):
                total_downloaded += 1
                total_size_gb += config['size_gb']
        else:
            logger.info(f"‚úì {config['description']} d√©j√† pr√©sent ({current_status[model_key]['size_mb']}MB)")
    
    # V√©rification finale
    logger.info("\nüîç V√©rification finale...")
    final_status = verify_local_models()
    
    # Rapport de t√©l√©chargement
    logger.info(f"\nüìä Rapport t√©l√©chargement:")
    logger.info(f"   Mod√®les t√©l√©charg√©s: {total_downloaded}")
    logger.info(f"   Taille totale: {total_size_gb:.2f}GB")
    logger.info(f"   Dossier: {MODELS_DIR}")
    
    # Validation finale
    all_ok = all(status["status"] == "OK" for status in final_status.values())
    if all_ok:
        logger.success("üéâ Tous les mod√®les DONUT sont pr√™ts pour √âtape 3!")
        return True
    else:
        missing = [k for k, v in final_status.items() if v["status"] == "MISSING"]
        logger.error(f"‚ùå Mod√®les manquants: {missing}")
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)